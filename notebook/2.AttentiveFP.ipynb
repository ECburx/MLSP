{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## AttentiveFP"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3761c2af8301e88"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from data.featurization.dgl_Graph import DGL_Graph\n",
    "from model.dgl.AttentiveFP import AttentiveFP\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score, cohen_kappa_score\n",
    "from sklearn.model_selection import KFold\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5158538f5a27ae2c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Regression Problems"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd1176a225d67a17"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trn = pd.read_csv(\"../data/trn.reg.csv.gz\", compression='gzip', low_memory=False)\n",
    "tst = pd.read_csv(\"../data/tst.reg.csv.gz\", compression='gzip', low_memory=False)\n",
    "\n",
    "trn_X = trn[\"SMILES\"]\n",
    "tst_X = tst[\"SMILES\"]\n",
    "trn_y = trn[\"LogS\"]\n",
    "tst_y = tst[\"LogS\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e54964276d9a6e2b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "featurizer = DGL_Graph(\n",
    "    graph_type=\"BI_GRAPH\",\n",
    "    featurize_type=\"Canonical\",\n",
    "    self_loop=True\n",
    ")\n",
    "trn_X = featurizer.convert(trn_X)\n",
    "tst_X = featurizer.convert(tst_X)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ccbe58e889ea165",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hyper-parameter Tuning."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c04bfa728bcc39e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tune_space = {\n",
    "    \"dropout\": hp.uniform(\"attn_drops\", 0, 1),\n",
    "    \"graph_feat_size\": hp.choice(\"graph_feat_size\", [200, 400, 600]),\n",
    "    \"num_layers\": hp.randint(\"num_layers\", 2, 8),\n",
    "    \"num_timesteps\": hp.randint(\"num_timesteps\", 2, 8),\n",
    "    \"lr\": hp.choice(\"lr\", [0.1, 0.01, 0.001]),\n",
    "    \"weight_decay\": hp.uniform(\"weight_decay\", 0, 1),\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "674589526cf1d294",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def tune_obj(space):\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    rmse = []\n",
    "\n",
    "    for trn_idx, val_idx in kf.split(trn_X):\n",
    "        tX, vX = trn_X[trn_idx], trn_X[val_idx]\n",
    "        ty, vy = trn_y[trn_idx], trn_y[val_idx]\n",
    "\n",
    "        model = AttentiveFP(\n",
    "            n_tasks=1,\n",
    "            node_feat_size=featurizer.get_node_feat_size(),\n",
    "            edge_feat_size=featurizer.get_edge_feat_size(),\n",
    "            graph_feat_size=space[\"graph_feat_size\"],\n",
    "            num_layers=space[\"num_layers\"],\n",
    "            num_timesteps=space[\"num_timesteps\"],\n",
    "            dropout=space[\"dropout\"],\n",
    "            lr=space[\"lr\"],\n",
    "            weight_decay=space[\"weight_decay\"],\n",
    "            batch_size=128,\n",
    "        )\n",
    "\n",
    "        scores = model.fit(tX, ty,\n",
    "                           val_X=vX, val_y=vy,\n",
    "                           epochs=800, min_epochs=500, early_stop_epochs=20, verbose=False)\n",
    "        rmse.append(scores[\"rmse\"][-1])\n",
    "\n",
    "    return {\"loss\": np.mean(rmse), 'status': STATUS_OK}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5f511447725580f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best_params = fmin(\n",
    "    fn=tune_obj,\n",
    "    space=tune_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=1,\n",
    "    trials=trials\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10b49423daeba75d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "best_params"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6465cf599db1cab"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    \"graph_feat_size\": 600,\n",
    "    \"num_layers\": 5,\n",
    "    \"num_timesteps\": 2,\n",
    "    \"dropout\": 0.2106440254404503,\n",
    "    \"lr\": 0.001,\n",
    "    \"weight_decay\": 0.0002571348715221869,\n",
    "    \"batch_size\": 128,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43bb3178eb626ad2",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "K-fold CV."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8fc3bee0ffee606"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def k_fold_CV(n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "    rmse, r2 = [], []\n",
    "\n",
    "    for trn_idx, val_idx in kf.split(trn_X):\n",
    "        tX, vX = trn_X[trn_idx], trn_X[val_idx]\n",
    "        ty, vy = trn_y[trn_idx], trn_y[val_idx]\n",
    "\n",
    "        model = AttentiveFP(\n",
    "            n_tasks=1,\n",
    "            node_feat_size=featurizer.get_node_feat_size(),\n",
    "            edge_feat_size=featurizer.get_edge_feat_size(),\n",
    "            graph_feat_size=best_params[\"graph_feat_size\"],\n",
    "            num_layers=best_params[\"num_layers\"],\n",
    "            num_timesteps=best_params[\"num_timesteps\"],\n",
    "            dropout=best_params[\"dropout\"],\n",
    "            lr=best_params[\"lr\"],\n",
    "            weight_decay=best_params[\"weight_decay\"],\n",
    "            batch_size=128,\n",
    "        )\n",
    "        model.fit(tX, ty, val_X=vX, val_y=vy, epochs=400)\n",
    "        pred_val = model.predict(vX).cpu()\n",
    "\n",
    "        rmse.append(root_mean_squared_error(vy, pred_val))\n",
    "        r2.append(r2_score(vy, pred_val))\n",
    "\n",
    "    return pd.DataFrame({\"rmse\": rmse, \"r2\": r2})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2555086e0cb555f0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pd.concat([k_fold_CV() for _ in range(10)])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ebd61e1e6fda206",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Prediction and estimation."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77dab59a18269835"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def predict():\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    prediction = []\n",
    "\n",
    "    for trn_idx, val_idx in kf.split(trn_X):\n",
    "        tX, vX = trn_X[trn_idx], trn_X[val_idx]\n",
    "        ty, vy = trn_y[trn_idx], trn_y[val_idx]\n",
    "\n",
    "        model = AttentiveFP(\n",
    "            n_tasks=1,\n",
    "            node_feat_size=featurizer.get_node_feat_size(),\n",
    "            edge_feat_size=featurizer.get_edge_feat_size(),\n",
    "            graph_feat_size=best_params[\"graph_feat_size\"],\n",
    "            num_layers=best_params[\"num_layers\"],\n",
    "            num_timesteps=best_params[\"num_timesteps\"],\n",
    "            dropout=best_params[\"dropout\"],\n",
    "            lr=best_params[\"lr\"],\n",
    "            weight_decay=best_params[\"weight_decay\"],\n",
    "            batch_size=128,\n",
    "        )\n",
    "        model.fit(tX, ty, val_X=vX, val_y=vy, epochs=800, min_epochs=400, early_stop_epochs=20)\n",
    "        prediction.append(model.predict(tst_X))\n",
    "\n",
    "    return [torch.mean(pred_i).item() for pred_i in torch.cat(prediction, 1)]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "932fdf4143db9a79",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "preds = [predict() for _ in range(50)]\n",
    "preds = pd.concat([pd.Series(p) for p in preds], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46ccb12e1509c7c8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rmse, r2 = defaultdict(list), defaultdict(list)\n",
    "\n",
    "for pred in [preds[c] for c in preds.columns]:\n",
    "    df = pd.DataFrame({\"pred\": pred, \"set\": tst[\"set\"], \"true\": tst[\"LogS\"]})\n",
    "    for s in df[\"set\"].unique():\n",
    "        p = df[df[\"set\"] == s]\n",
    "        rmse[s].append(root_mean_squared_error(p[\"true\"], p[\"pred\"]))\n",
    "        r2[s].append(r2_score(p[\"true\"], p[\"pred\"]))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1cc0cba2019818d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for s in rmse.keys():\n",
    "    print(f\"[{s}] rmse:{np.mean(rmse[s]):.2f}±{np.std(rmse[s]):.2f} r2:{np.mean(r2[s]):.2f}±{np.std(r2[s]):.2f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d931a8daca467c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def subplot(x, y, ax):\n",
    "    ax.scatter(x, y)\n",
    "    ax.set_xlim((min(min(x), min(y)) - 0.1, max(max(x), max(y)) + 0.1))\n",
    "    ax.set_ylim((min(min(x), min(y)) - 0.1, max(max(x), max(y)) + 0.1))\n",
    "    x0, x1 = ax.get_xlim()\n",
    "    y0, y1 = ax.get_ylim()\n",
    "    ax.set_aspect(abs(x1 - x0) / abs(y1 - y0))\n",
    "    ax.grid(which='major', linestyle='--')\n",
    "    ax.plot([min(min(x), min(y)), max(max(x), max(y))], [min(min(x), min(y)), max(max(x), max(y))], 'k')\n",
    "    a, b = np.polyfit(x, y, 1)\n",
    "    y_fit = a * x + b\n",
    "    ax.plot(x, y_fit)\n",
    "    ax.set_xlabel(\"log$S$ Experimental\")\n",
    "    ax.set_ylabel(\"log$S$ Predicted\")\n",
    "\n",
    "\n",
    "model_name = \"AttentiveFP\"\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(5 * 3, 5))\n",
    "df = pd.DataFrame({\"pred\": preds.iloc[:, np.argmin(np.array(list(rmse.values())).mean(axis=0))],\n",
    "                   \"set\": tst[\"set\"], \"true\": tst[\"LogS\"]})\n",
    "for s, ax in zip(rmse.keys(), axs):\n",
    "    idx = tst[tst[\"set\"] == s].index\n",
    "    t = df[\"true\"].loc[idx]\n",
    "    p = df[\"pred\"].loc[idx]\n",
    "    subplot(t, p, ax)\n",
    "    ax.grid(False)\n",
    "    ax.set_title(f\"{s} ({model_name})   \"\n",
    "                 f\"RMSE: {root_mean_squared_error(t, p):.2f}, \"\n",
    "                 f\"R$^2$: {r2_score(t, p):.2f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "537da348e5abb6a4",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification Problem"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c7a7f00830c26d0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trn = pd.concat([pd.read_csv(f\"../data/trn.EUOS-SLAS.Part{i}.csv.gz\") for i in range(1, 9)])\n",
    "tst = pd.concat([pd.read_csv(f\"../data/tst.EUOS-SLAS.Part{i}.csv.gz\") for i in range(1, 5)])\n",
    "\n",
    "trn_X = trn[\"SMILES\"]\n",
    "tst_X = tst[\"SMILES\"]\n",
    "trn_y = trn[\"solubility\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "661457333094202d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "featurizer = DGL_Graph(\n",
    "    graph_type=\"BI_GRAPH\",\n",
    "    featurize_type=\"Canonical\",\n",
    "    self_loop=True\n",
    ")\n",
    "trn_X = featurizer.convert(trn_X)\n",
    "tst_X = featurizer.convert(tst_X)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8158961526780ce",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hyper-parameter Tuning."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf2ede900c895af1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def tune_obj(space):\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    qck = []\n",
    "\n",
    "    for trn_idx, val_idx in kf.split(trn_X):\n",
    "        tX, vX = trn_X[trn_idx], trn_X[val_idx]\n",
    "        ty, vy = trn_y[trn_idx], trn_y[val_idx]\n",
    "\n",
    "        model = AttentiveFP(\n",
    "            n_tasks=3,\n",
    "            node_feat_size=featurizer.get_node_feat_size(),\n",
    "            edge_feat_size=featurizer.get_edge_feat_size(),\n",
    "            graph_feat_size=space[\"graph_feat_size\"],\n",
    "            num_layers=space[\"num_layers\"],\n",
    "            num_timesteps=space[\"num_timesteps\"],\n",
    "            dropout=space[\"dropout\"],\n",
    "            lr=space[\"lr\"],\n",
    "            weight_decay=space[\"weight_decay\"],\n",
    "            batch_size=128,\n",
    "        )\n",
    "        scores = model.fit(tX, ty,\n",
    "                           val_X=vX, val_y=vy,\n",
    "                           epochs=800, min_epochs=500, early_stop_epochs=10, verbose=False)\n",
    "        qck.append(scores[\"qck\"][-1])\n",
    "\n",
    "    return {\"loss\": np.mean(qck), 'status': STATUS_OK}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe15d2f558e16a9a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best_params = fmin(\n",
    "    fn=tune_obj,\n",
    "    space=tune_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=500,\n",
    "    trials=trials\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14f092f07f16b98b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "K-fold CV."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28e03732ae79bc2a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def k_fold_CV(n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "    qck = []\n",
    "\n",
    "    for trn_idx, val_idx in kf.split(trn_X):\n",
    "        tX, vX = trn_X[trn_idx], trn_X[val_idx]\n",
    "        ty, vy = trn_y[trn_idx], trn_y[val_idx]\n",
    "\n",
    "        model = AttentiveFP(\n",
    "            n_tasks=3,\n",
    "            node_feat_size=featurizer.get_node_feat_size(),\n",
    "            edge_feat_size=featurizer.get_edge_feat_size(),\n",
    "            graph_feat_size=best_params[\"graph_feat_size\"],\n",
    "            num_layers=best_params[\"num_layers\"],\n",
    "            num_timesteps=best_params[\"num_timesteps\"],\n",
    "            dropout=best_params[\"dropout\"],\n",
    "            lr=best_params[\"lr\"],\n",
    "            weight_decay=best_params[\"weight_decay\"],\n",
    "            batch_size=128,\n",
    "        )\n",
    "        model.fit(tX, ty, val_X=vX, val_y=vy, epochs=400)\n",
    "        pred_val = model.predict(vX).cpu()\n",
    "        pred_val = torch.argmax(pred_val, dim=1)\n",
    "\n",
    "        qck.append(cohen_kappa_score(vy, pred_val, weights=\"quadratic\"))\n",
    "\n",
    "    return pd.DataFrame({\"qck\": qck})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53351e2a76b25990",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pd.concat([k_fold_CV() for _ in range(10)])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c09935b5f5ff794c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Prediction and estimation."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d1f1202ce5e0be5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def predict():\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    prediction = []\n",
    "\n",
    "    for trn_idx, val_idx in kf.split(trn_X):\n",
    "        tX, vX = trn_X[trn_idx], trn_X[val_idx]\n",
    "        ty, vy = trn_y[trn_idx], trn_y[val_idx]\n",
    "\n",
    "        model = AttentiveFP(\n",
    "            n_tasks=3,\n",
    "            node_feat_size=featurizer.get_node_feat_size(),\n",
    "            edge_feat_size=featurizer.get_edge_feat_size(),\n",
    "            graph_feat_size=best_params[\"graph_feat_size\"],\n",
    "            num_layers=best_params[\"num_layers\"],\n",
    "            num_timesteps=best_params[\"num_timesteps\"],\n",
    "            dropout=best_params[\"dropout\"],\n",
    "            lr=best_params[\"lr\"],\n",
    "            weight_decay=best_params[\"weight_decay\"],\n",
    "            batch_size=128,\n",
    "        )\n",
    "        model.fit(tX, ty, val_X=vX, val_y=vy, epochs=800, min_epochs=400, early_stop_epochs=20)\n",
    "        prediction.append(model.predict(tst_X))\n",
    "\n",
    "    return torch.argmax(torch.stack(prediction).mean(dim=0), dim=1).cpu()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd3717862ee01681"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "preds = [predict() for _ in range(50)]\n",
    "preds = pd.DataFrame([p.numpy().tolist() for p in preds]).transpose()\n",
    "preds"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e98ded577730bc9d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Upload the predictions to the challenge to get feedback on the model's performance."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8fe24e7b8f3fc23f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
