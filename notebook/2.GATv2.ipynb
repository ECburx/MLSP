{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## GATv2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54f1d9106485affc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from data.featurization.dgl_Graph import DGL_Graph\n",
    "from model.dgl.GATv2 import GATv2\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score, cohen_kappa_score\n",
    "from sklearn.model_selection import KFold\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2912e50ce394a415",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Regression Problems"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99e33a11f596587c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trn = pd.read_csv(\"../data/trn.reg.csv.gz\", compression='gzip', low_memory=False)\n",
    "tst = pd.read_csv(\"../data/tst.reg.csv.gz\", compression='gzip', low_memory=False)\n",
    "\n",
    "trn_X = trn[\"SMILES\"]\n",
    "tst_X = tst[\"SMILES\"]\n",
    "trn_y = trn[\"LogS\"]\n",
    "tst_y = tst[\"LogS\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfb24f8cac25a755",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "featurizer = DGL_Graph(\n",
    "    graph_type=\"BI_GRAPH\",\n",
    "    featurize_type=\"Canonical\",\n",
    "    self_loop=True\n",
    ")\n",
    "trn_X = featurizer.convert(trn_X)\n",
    "tst_X = featurizer.convert(tst_X)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acd31a301afcda18",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hyper-parameter Tuning."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed23996a13350475"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tune_space = {\n",
    "    \"num_heads\": hp.randint(\"num_heads\", 2, 6),\n",
    "    \"hidden_feats\": hp.choice(\"hidden_feats\", [[64], [64, 32], [128, 64, 32], [64, 64], [128, 64]]),\n",
    "    \"feat_drops\": hp.uniform(\"feat_drops\", 0, 1),\n",
    "    \"attn_drops\": hp.uniform(\"attn_drops\", 0, 1),\n",
    "    \"alphas\": hp.uniform(\"alphas\", 0, 1),\n",
    "    \"residuals\": hp.choice(\"residuals\", [True, False]),\n",
    "    \"agg_modes\": hp.choice(\"agg_modes\", [\"flatten\", \"mean\"]),\n",
    "    \"biases\": hp.choice(\"biases\", [True, False]),\n",
    "    \"allow_zero_in_degree\": hp.choice(\"allow_zero_in_degree\", [True, False]),\n",
    "    \"share_weights\": hp.choice(\"share_weights\", [True, False]),\n",
    "    \"get_attention\": False,\n",
    "    \"lr\": hp.choice(\"lr\", [0.1, 0.01, 0.001]),\n",
    "    \"weight_decay\": hp.uniform(\"weight_decay\", 0, 1),\n",
    "    \"batch_size\": 128,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa598fa9eca468de",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def tune_obj(space):\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    rmse = []\n",
    "\n",
    "    for trn_idx, val_idx in kf.split(trn_X):\n",
    "        tX, vX = trn_X[trn_idx], trn_X[val_idx]\n",
    "        ty, vy = trn_y[trn_idx], trn_y[val_idx]\n",
    "\n",
    "        model = GATv2(\n",
    "            n_tasks=1,\n",
    "            in_feats=featurizer.get_node_feat_size(),\n",
    "            hidden_feats=space[\"hidden_feats\"],\n",
    "            num_heads=space[\"num_heads\"],\n",
    "            feat_drops=space[\"feat_drops\"],\n",
    "            attn_drops=space[\"attn_drops\"],\n",
    "            alphas=space[\"alphas\"],\n",
    "            residuals=space[\"residuals\"],\n",
    "            biases=space[\"biases\"],\n",
    "            agg_modes=space[\"agg_modes\"],\n",
    "            allow_zero_in_degree=space[\"allow_zero_in_degree\"],\n",
    "            share_weights=space[\"share_weights\"],\n",
    "            predictor_out_feats=128,\n",
    "            predictor_dropout=0,\n",
    "            get_attention=space[\"get_attention\"],\n",
    "            lr=space[\"lr\"],\n",
    "            weight_decay=space[\"weight_decay\"],\n",
    "            batch_size=128,\n",
    "        )\n",
    "        model.fit(tX, ty,\n",
    "                  epochs=800, min_epochs=400, early_stop_epochs=20, verbose=False)\n",
    "        rmse.append(root_mean_squared_error(vy, model.predict(vX).cpu()))\n",
    "\n",
    "    return {\"loss\": np.mean(rmse), 'status': STATUS_OK}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37278d4814629b33",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best_params = fmin(\n",
    "    fn=tune_obj,\n",
    "    space=tune_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=500,\n",
    "    trials=trials\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a153d688b043baa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "best_params"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73730167f00bb255"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    \"num_heads\": 5,\n",
    "    \"hidden_feats\": [128, 64],\n",
    "    \"feat_drops\": 0.028992495735341864,\n",
    "    \"attn_drops\": 0.5312766550561073,\n",
    "    \"alphas\": 0.9823528273902176,\n",
    "    \"residuals\": True,\n",
    "    \"biases\": True,\n",
    "    \"agg_modes\": \"flatten\",\n",
    "    \"allow_zero_in_degree\": False,\n",
    "    \"share_weights\": False,\n",
    "    \"get_attention\": False,\n",
    "    \"lr\": 0.001,\n",
    "    \"weight_decay\": 0.007911109145324904,\n",
    "    \"batch_size\": 128,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d72320707598e96",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def k_fold_CV(n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "    rmse, r2 = [], []\n",
    "\n",
    "    for trn_idx, val_idx in kf.split(trn_X):\n",
    "        tX, vX = trn_X[trn_idx], trn_X[val_idx]\n",
    "        ty, vy = trn_y[trn_idx], trn_y[val_idx]\n",
    "\n",
    "        model = GATv2(\n",
    "            n_tasks=1,\n",
    "            in_feats=featurizer.get_node_feat_size(),\n",
    "            hidden_feats=best_params[\"hidden_feats\"],\n",
    "            num_heads=best_params[\"num_heads\"],\n",
    "            feat_drops=best_params[\"feat_drops\"],\n",
    "            attn_drops=best_params[\"attn_drops\"],\n",
    "            alphas=best_params[\"alphas\"],\n",
    "            residuals=best_params[\"residuals\"],\n",
    "            biases=best_params[\"biases\"],\n",
    "            agg_modes=best_params[\"agg_modes\"],\n",
    "            allow_zero_in_degree=best_params[\"allow_zero_in_degree\"],\n",
    "            share_weights=best_params[\"share_weights\"],\n",
    "            predictor_out_feats=128,\n",
    "            predictor_dropout=0,\n",
    "            get_attention=best_params[\"get_attention\"],\n",
    "            lr=best_params[\"lr\"],\n",
    "            weight_decay=best_params[\"weight_decay\"],\n",
    "            batch_size=128,\n",
    "        )\n",
    "        model.fit(tX, ty, val_X=vX, val_y=vy, epochs=400)\n",
    "        pred_val = model.predict(vX).cpu()\n",
    "\n",
    "        rmse.append(root_mean_squared_error(vy, pred_val))\n",
    "        r2.append(r2_score(vy, pred_val))\n",
    "\n",
    "    return pd.DataFrame({\"rmse\": rmse, \"r2\": r2})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a05f9fd281ad1c8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pd.concat([k_fold_CV() for _ in range(10)])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30398fdd2f1e04a7",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Prediction and estimation."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "613981af47ce7638"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def predict():\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    prediction = []\n",
    "\n",
    "    for trn_idx, val_idx in kf.split(trn_X):\n",
    "        tX, vX = trn_X[trn_idx], trn_X[val_idx]\n",
    "        ty, vy = trn_y[trn_idx], trn_y[val_idx]\n",
    "\n",
    "        model = GATv2(\n",
    "            n_tasks=1,\n",
    "            in_feats=featurizer.get_node_feat_size(),\n",
    "            hidden_feats=best_params[\"hidden_feats\"],\n",
    "            num_heads=best_params[\"num_heads\"],\n",
    "            feat_drops=best_params[\"feat_drops\"],\n",
    "            attn_drops=best_params[\"attn_drops\"],\n",
    "            alphas=best_params[\"alphas\"],\n",
    "            residuals=best_params[\"residuals\"],\n",
    "            biases=best_params[\"biases\"],\n",
    "            agg_modes=best_params[\"agg_modes\"],\n",
    "            allow_zero_in_degree=best_params[\"allow_zero_in_degree\"],\n",
    "            share_weights=best_params[\"share_weights\"],\n",
    "            predictor_out_feats=128,\n",
    "            predictor_dropout=0,\n",
    "            get_attention=best_params[\"get_attention\"],\n",
    "            lr=best_params[\"lr\"],\n",
    "            weight_decay=best_params[\"weight_decay\"],\n",
    "            batch_size=128,\n",
    "        )\n",
    "        model.fit(tX, ty, val_X=vX, val_y=vy, epochs=800, min_epochs=400, early_stop_epochs=20)\n",
    "        prediction.append(model.predict(tst_X).cpu())\n",
    "\n",
    "    return [torch.mean(pred_i).item() for pred_i in torch.cat(prediction, 1)]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41d5cdf95ff443c8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "preds = [predict() for _ in range(10)]\n",
    "preds = pd.concat([pd.Series(p) for p in preds], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51a9d647263fbcdb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rmse, r2 = defaultdict(list), defaultdict(list)\n",
    "\n",
    "for pred in [preds[c] for c in preds.columns]:\n",
    "    df = pd.DataFrame({\"pred\": pred, \"set\": tst[\"set\"], \"true\": tst[\"LogS\"]})\n",
    "    for s in df[\"set\"].unique():\n",
    "        p = df[df[\"set\"] == s]\n",
    "        rmse[s].append(root_mean_squared_error(p[\"true\"], p[\"pred\"]))\n",
    "        r2[s].append(r2_score(p[\"true\"], p[\"pred\"]))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70fdfabf8c883811",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for s in rmse.keys():\n",
    "    print(f\"[{s}] rmse:{np.mean(rmse[s]):.2f}±{np.std(rmse[s]):.2f} r2:{np.mean(r2[s]):.2f}±{np.std(r2[s]):.2f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69a5d970c25fcb6b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def subplot(x, y, ax):\n",
    "    ax.scatter(x, y)\n",
    "    ax.set_xlim((min(min(x), min(y)) - 0.1, max(max(x), max(y)) + 0.1))\n",
    "    ax.set_ylim((min(min(x), min(y)) - 0.1, max(max(x), max(y)) + 0.1))\n",
    "    x0, x1 = ax.get_xlim()\n",
    "    y0, y1 = ax.get_ylim()\n",
    "    ax.set_aspect(abs(x1 - x0) / abs(y1 - y0))\n",
    "    ax.grid(which='major', linestyle='--')\n",
    "    ax.plot([min(min(x), min(y)), max(max(x), max(y))], [min(min(x), min(y)), max(max(x), max(y))], 'k')\n",
    "    a, b = np.polyfit(x, y, 1)\n",
    "    y_fit = a * x + b\n",
    "    ax.plot(x, y_fit)\n",
    "    ax.set_xlabel(\"log$S$ Experimental\")\n",
    "    ax.set_ylabel(\"log$S$ Predicted\")\n",
    "\n",
    "\n",
    "model_name = \"GATv2\"\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(5 * 3, 5))\n",
    "\n",
    "df = pd.DataFrame({\"pred\": preds.iloc[:, np.argmin(np.array(list(rmse.values())).mean(axis=0))],\n",
    "                   \"set\": tst[\"set\"], \"true\": tst[\"LogS\"]})\n",
    "for s, ax in zip(rmse.keys(), axs):\n",
    "    idx = tst[tst[\"set\"] == s].index\n",
    "    t = df[\"true\"].loc[idx]\n",
    "    p = df[\"pred\"].loc[idx]\n",
    "    subplot(t, p, ax)\n",
    "    ax.grid(False)\n",
    "    ax.set_title(f\"{s} ({model_name})   \"\n",
    "                 f\"RMSE: {root_mean_squared_error(t, p):.3f}, \"\n",
    "                 f\"R$^2$: {r2_score(t, p):.3f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2f931de1d33e9bd",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification Problem"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1159404695bd148"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trn = pd.concat([pd.read_csv(f\"../data/trn.EUOS-SLAS.Part{i}.csv.gz\") for i in range(1, 9)])\n",
    "tst = pd.concat([pd.read_csv(f\"../data/tst.EUOS-SLAS.Part{i}.csv.gz\") for i in range(1, 5)])\n",
    "\n",
    "trn_X = trn[\"SMILES\"]\n",
    "tst_X = tst[\"SMILES\"]\n",
    "trn_y = trn[\"solubility\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "165e0e41b7b47c98",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "featurizer = DGL_Graph(\n",
    "    graph_type=\"BI_GRAPH\",\n",
    "    featurize_type=\"Canonical\",\n",
    "    self_loop=True\n",
    ")\n",
    "trn_X = featurizer.convert(trn_X)\n",
    "tst_X = featurizer.convert(tst_X)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8a871cfd2546cfd",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hyper-parameter Tuning."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "739bc02c900d3836"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def tune_obj(space):\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    qck = []\n",
    "\n",
    "    for trn_idx, val_idx in kf.split(trn_X):\n",
    "        tX, vX = trn_X[trn_idx], trn_X[val_idx]\n",
    "        ty, vy = trn_y[trn_idx], trn_y[val_idx]\n",
    "\n",
    "        model = GATv2(\n",
    "            n_tasks=1,\n",
    "            in_feats=featurizer.get_node_feat_size(),\n",
    "            hidden_feats=space[\"hidden_feats\"],\n",
    "            num_heads=space[\"num_heads\"],\n",
    "            feat_drops=space[\"feat_drops\"],\n",
    "            attn_drops=space[\"attn_drops\"],\n",
    "            alphas=space[\"alphas\"],\n",
    "            residuals=space[\"residuals\"],\n",
    "            biases=space[\"biases\"],\n",
    "            agg_modes=space[\"agg_modes\"],\n",
    "            allow_zero_in_degree=space[\"allow_zero_in_degree\"],\n",
    "            share_weights=space[\"share_weights\"],\n",
    "            predictor_out_feats=128,\n",
    "            predictor_dropout=0,\n",
    "            get_attention=space[\"get_attention\"],\n",
    "            lr=space[\"lr\"],\n",
    "            weight_decay=space[\"weight_decay\"],\n",
    "            batch_size=128,\n",
    "        )\n",
    "        scores = model.fit(tX, ty,\n",
    "                           val_X=vX, val_y=vy,\n",
    "                           epochs=800, min_epochs=500, early_stop_epochs=10, verbose=False)\n",
    "        qck.append(scores[\"qck\"][-1])\n",
    "\n",
    "    return {\"loss\": np.mean(qck), 'status': STATUS_OK}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37055a116dbdf590",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best_params = fmin(\n",
    "    fn=tune_obj,\n",
    "    space=tune_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=500,\n",
    "    trials=trials\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c232b171daf859af",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "best_params"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8821d9e8a5263ed6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Prediction and estimation."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3541fbf02548a94"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def predict():\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    prediction = []\n",
    "\n",
    "    for trn_idx, val_idx in kf.split(trn_X):\n",
    "        tX, vX = trn_X[trn_idx], trn_X[val_idx]\n",
    "        ty, vy = trn_y[trn_idx], trn_y[val_idx]\n",
    "\n",
    "        model = GATv2(\n",
    "            n_tasks=1,\n",
    "            in_feats=featurizer.get_node_feat_size(),\n",
    "            hidden_feats=best_params[\"hidden_feats\"],\n",
    "            num_heads=best_params[\"num_heads\"],\n",
    "            feat_drops=best_params[\"feat_drops\"],\n",
    "            attn_drops=best_params[\"attn_drops\"],\n",
    "            alphas=best_params[\"alphas\"],\n",
    "            residuals=best_params[\"residuals\"],\n",
    "            biases=best_params[\"biases\"],\n",
    "            agg_modes=best_params[\"agg_modes\"],\n",
    "            allow_zero_in_degree=best_params[\"allow_zero_in_degree\"],\n",
    "            share_weights=best_params[\"share_weights\"],\n",
    "            predictor_out_feats=128,\n",
    "            predictor_dropout=0,\n",
    "            get_attention=best_params[\"get_attention\"],\n",
    "            lr=best_params[\"lr\"],\n",
    "            weight_decay=best_params[\"weight_decay\"],\n",
    "            batch_size=128,\n",
    "        )\n",
    "        model.fit(tX, ty, val_X=vX, val_y=vy, epochs=800, min_epochs=400, early_stop_epochs=20)\n",
    "        prediction.append(model.predict(tst_X))\n",
    "\n",
    "    return torch.argmax(torch.stack(prediction).mean(dim=0), dim=1).cpu()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T00:47:32.423685Z",
     "start_time": "2024-05-14T00:47:32.419890Z"
    }
   },
   "id": "c3f7f80dcb281dcf",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "preds = [predict() for _ in range(50)]\n",
    "preds = pd.DataFrame([p.numpy().tolist() for p in preds]).transpose()\n",
    "preds"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "296f52e3f00adbc8",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Upload the predictions to the challenge to get feedback on the model's performance."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "322cdbd9e69250b5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
